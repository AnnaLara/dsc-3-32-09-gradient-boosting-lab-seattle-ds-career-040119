{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we'll learn how to use both Adaboost and Gradient Boosting Classifiers from scikit-learn!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Compare and contrast Adaboost and Gradient Boosting\n",
    "* Use adaboost to make predictions on a dataset\n",
    "* Use Gradient Boosting to make predictions on a dataset\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "In this lab, we'll learn how to use Boosting algorithms to make classifications on the [Pima Indians Dataset](http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.names). You will find the data stored within the file `pima-indians-diabetes.csv`. Our goal is to use boosting algorithms to classify each person as having or not having diabetes. Let's get started!\n",
    "\n",
    "We'll begin by importing everything we need for this lab. In the cell below:\n",
    "\n",
    "* Import `numpy`, `pandas`, and `matplotlib.pyplot`, and set the standard alias for each. Also set matplotlib visualizations to display inline. \n",
    "* Set a random seed of `0` by using `np.random.seed(0)`\n",
    "* Import `train_test_split` and `cross_val_score` from `sklearn.model_selection`\n",
    "* Import `StandardScaler` from `sklearn.preprocessing`\n",
    "* Import `AdaboostClassifier` and `GradientBoostingClassifier` from `sklearn.ensemble`\n",
    "* Import `accuracy_score`, `f1_score`, `confusion_matrix`, and `classification_report` from `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/48/4e1461d828baf41d609efaa720d20090ac6ec346b5daad3c88e243e2207e/sklearn_pandas-1.8.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from sklearn-pandas) (1.16.3)\n",
      "Requirement already satisfied: pandas>=0.11.0 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from sklearn-pandas) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from sklearn-pandas) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.15.0 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from sklearn-pandas) (0.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from pandas>=0.11.0->sklearn-pandas) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from pandas>=0.11.0->sklearn-pandas) (2018.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/learn-env/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.11.0->sklearn-pandas) (1.11.0)\n",
      "Installing collected packages: sklearn-pandas\n",
      "Successfully installed sklearn-pandas-1.8.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-pandas\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "%matplotlib inline\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use pandas to read in the data stored in `pima-indians-diabetes.csv` and store it in a DataFrame. Display the head to inspect the data we've imported and ensure everything loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning, Exploration, and Preprocessing\n",
    "\n",
    "The target we're trying to predict is the `'Outcome'` column. A `1` denotes a patient with diabetes. \n",
    "\n",
    "By now, you're quite familiar with exploring and preprocessing a dataset, so we won't hold your hand for this step. \n",
    "\n",
    "In the following cells:\n",
    "\n",
    "* Store our target column in a separate variable and remove it from the dataset\n",
    "* Check for null values and deal with them as you see fit (if any exist)\n",
    "* Check the distribution of our target\n",
    "* Scale the dataset\n",
    "* Split the dataset into training and testing sets, with a `test_size` of `0.25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Outcome'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scaler = None\n",
    "#scaled_df = None\n",
    "#scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import sklearn_pandas\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=0, strategy='mean')\n",
    "\n",
    "mapper = sklearn_pandas.DataFrameMapper([\n",
    "    ([\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \n",
    "      \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"], imp_mean),\n",
    "    ([\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \n",
    "      \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"], StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameMapper(default=False, df_out=False,\n",
       "        features=[(['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'], SimpleImputer(copy=True, fill_value=None, missing_values=0, strategy='mean',\n",
       "       verbose=0)), (['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'], StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "        input_df=False, sparse=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>86</td>\n",
       "      <td>30</td>\n",
       "      <td>105</td>\n",
       "      <td>39.1</td>\n",
       "      <td>0.251</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.4</td>\n",
       "      <td>0.205</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>158</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.292</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.532</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>34.2</td>\n",
       "      <td>1.292</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>275</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1.600</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>7</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>145</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.163</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>54</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.205</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>0.686</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.542</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>10</td>\n",
       "      <td>148</td>\n",
       "      <td>84</td>\n",
       "      <td>48</td>\n",
       "      <td>237</td>\n",
       "      <td>37.6</td>\n",
       "      <td>1.001</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>7</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>40</td>\n",
       "      <td>105</td>\n",
       "      <td>37.2</td>\n",
       "      <td>0.204</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>5</td>\n",
       "      <td>158</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.207</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.252</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>53</td>\n",
       "      <td>45.2</td>\n",
       "      <td>0.089</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5</td>\n",
       "      <td>139</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>140</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.411</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.283</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>540</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.240</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>7</td>\n",
       "      <td>129</td>\n",
       "      <td>68</td>\n",
       "      <td>49</td>\n",
       "      <td>125</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.439</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>0.400</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>115</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.471</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>86</td>\n",
       "      <td>39</td>\n",
       "      <td>220</td>\n",
       "      <td>45.6</td>\n",
       "      <td>0.808</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>9</td>\n",
       "      <td>184</td>\n",
       "      <td>85</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.213</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>190</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.549</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>82</td>\n",
       "      <td>17</td>\n",
       "      <td>183</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.115</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>78</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.280</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>126</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.692</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.433</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>210</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.804</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>0.612</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2</td>\n",
       "      <td>106</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>119</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1.400</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.313</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>22</td>\n",
       "      <td>66</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.545</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>3</td>\n",
       "      <td>106</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.207</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.088</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.564</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>6</td>\n",
       "      <td>183</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.8</td>\n",
       "      <td>1.461</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>2</td>\n",
       "      <td>101</td>\n",
       "      <td>58</td>\n",
       "      <td>17</td>\n",
       "      <td>265</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0.614</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>0.376</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>8</td>\n",
       "      <td>197</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1.191</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>76</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.365</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>64</td>\n",
       "      <td>44</td>\n",
       "      <td>99</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.905</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>59</td>\n",
       "      <td>25.1</td>\n",
       "      <td>1.268</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.582</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>8</td>\n",
       "      <td>74</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.705</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.236</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.241</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>3</td>\n",
       "      <td>142</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.200</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>12</td>\n",
       "      <td>140</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>325</td>\n",
       "      <td>39.2</td>\n",
       "      <td>0.528</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>3</td>\n",
       "      <td>163</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>105</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.268</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>8</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>36</td>\n",
       "      <td>108</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.349</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "760            2       88             58             26       16  28.4   \n",
       "723            5      117             86             30      105  39.1   \n",
       "435            0      141              0              0        0  42.4   \n",
       "610            3      106             54             21      158  30.9   \n",
       "137            0       93             60             25       92  28.7   \n",
       "659            3       80             82             31       70  34.2   \n",
       "395            2      127             58             24      275  27.7   \n",
       "498            7      195             70             33      145  25.1   \n",
       "28            13      145             82             19      110  22.2   \n",
       "385            1      119             54             13       50  22.3   \n",
       "531            0      107             76              0        0  45.3   \n",
       "451            2      134             70              0        0  28.9   \n",
       "458           10      148             84             48      237  37.6   \n",
       "161            7      102             74             40      105  37.2   \n",
       "361            5      158             70              0        0  29.8   \n",
       "367            0      101             64             17        0  21.0   \n",
       "229            0      117             80             31       53  45.2   \n",
       "763           10      101             76             48      180  32.9   \n",
       "71             5      139             64             35      140  28.6   \n",
       "103            1       81             72             18       40  26.6   \n",
       "655            2      155             52             27      540  38.7   \n",
       "693            7      129             68             49      125  38.5   \n",
       "600            1      108             88             19        0  27.1   \n",
       "554            1       84             64             23      115  36.9   \n",
       "113            4       76             62              0        0  34.0   \n",
       "287            1      119             86             39      220  45.6   \n",
       "245            9      184             85             15        0  30.0   \n",
       "541            3      128             72             25      190  32.4   \n",
       "633            1      128             82             17      183  27.5   \n",
       "403            9       72             78             25        0  31.6   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "603            7      150             78             29      126  35.2   \n",
       "312            2      155             74             17       96  26.6   \n",
       "538            0      127             80             37      210  36.3   \n",
       "262            4       95             70             32        0  32.1   \n",
       "147            2      106             64             35      119  30.5   \n",
       "310            6       80             66             30        0  26.2   \n",
       "643            4       90              0              0        0  28.0   \n",
       "372            0       84             64             22       66  35.8   \n",
       "615            3      106             72              0        0  25.8   \n",
       "135            2      125             60             20      140  33.8   \n",
       "748            3      187             70             22      200  36.4   \n",
       "46             1      146             56              0        0  29.7   \n",
       "766            1      126             60              0        0  30.1   \n",
       "622            6      183             94              0        0  40.8   \n",
       "679            2      101             58             17      265  24.2   \n",
       "406            4      115             72              0        0  28.9   \n",
       "408            8      197             74              0        0  25.9   \n",
       "544            1       88             78             29       76  32.0   \n",
       "198            4      109             64             44       99  34.8   \n",
       "391            5      166             76              0        0  45.7   \n",
       "383            1       90             62             18       59  25.1   \n",
       "239            0      104             76              0        0  18.4   \n",
       "462            8       74             70             40       49  35.3   \n",
       "381            0      105             68             22        0  20.0   \n",
       "483            0       84             82             31      125  38.2   \n",
       "399            3      193             70             31        0  34.9   \n",
       "263            3      142             80             15        0  32.4   \n",
       "375           12      140             82             43      325  39.2   \n",
       "515            3      163             70             18      105  31.6   \n",
       "345            8      126             88             36      108  38.5   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "760                     0.766   22  \n",
       "723                     0.251   42  \n",
       "435                     0.205   29  \n",
       "610                     0.292   24  \n",
       "137                     0.532   22  \n",
       "659                     1.292   27  \n",
       "395                     1.600   25  \n",
       "498                     0.163   55  \n",
       "28                      0.245   57  \n",
       "385                     0.205   24  \n",
       "531                     0.686   24  \n",
       "451                     0.542   23  \n",
       "458                     1.001   51  \n",
       "161                     0.204   45  \n",
       "361                     0.207   63  \n",
       "367                     0.252   21  \n",
       "229                     0.089   24  \n",
       "763                     0.171   63  \n",
       "71                      0.411   26  \n",
       "103                     0.283   24  \n",
       "655                     0.240   25  \n",
       "693                     0.439   43  \n",
       "600                     0.400   24  \n",
       "554                     0.471   28  \n",
       "113                     0.391   25  \n",
       "287                     0.808   29  \n",
       "245                     1.213   49  \n",
       "541                     0.549   27  \n",
       "633                     0.115   22  \n",
       "403                     0.280   38  \n",
       "..                        ...  ...  \n",
       "603                     0.692   54  \n",
       "312                     0.433   27  \n",
       "538                     0.804   23  \n",
       "262                     0.612   24  \n",
       "147                     1.400   34  \n",
       "310                     0.313   41  \n",
       "643                     0.610   31  \n",
       "372                     0.545   21  \n",
       "615                     0.207   27  \n",
       "135                     0.088   31  \n",
       "748                     0.408   36  \n",
       "46                      0.564   29  \n",
       "766                     0.349   47  \n",
       "622                     1.461   45  \n",
       "679                     0.614   23  \n",
       "406                     0.376   46  \n",
       "408                     1.191   39  \n",
       "544                     0.365   29  \n",
       "198                     0.905   26  \n",
       "391                     0.340   27  \n",
       "383                     1.268   25  \n",
       "239                     0.582   27  \n",
       "462                     0.705   39  \n",
       "381                     0.236   22  \n",
       "483                     0.233   23  \n",
       "399                     0.241   25  \n",
       "263                     0.200   63  \n",
       "375                     0.528   58  \n",
       "515                     0.268   28  \n",
       "345                     0.349   49  \n",
       "\n",
       "[576 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrameMapper(default=False, df_out=False,\n",
       "        features=[(['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'], SimpleImputer(copy=True, fill_value=None, missing_values=0, strategy='mean',\n",
       "       verbose=0)), (['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age'], StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       "        input_df=False, sparse=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.24000000e+02,  6.00000000e+01,  3.20000000e+01, ...,\n",
       "         5.39482357e-01,  1.18646514e-01, -9.98159721e-01],\n",
       "       [ 1.47000000e+02,  7.40000000e+01,  2.50000000e+01, ...,\n",
       "         4.22147490e-01, -2.41304106e-01, -2.82763621e-01],\n",
       "       [ 1.32000000e+02,  7.80000000e+01,  2.88496241e+01, ...,\n",
       "         9.62173064e-02, -2.18981587e-01, -9.98159721e-01],\n",
       "       ...,\n",
       "       [ 1.24000000e+02,  7.00000000e+01,  2.00000000e+01, ...,\n",
       "        -5.55643061e-01, -6.06835356e-01,  1.94167113e-01],\n",
       "       [ 9.20000000e+01,  6.20000000e+01,  2.50000000e+01, ...,\n",
       "        -1.58558244e+00,  2.93564379e-02, -6.80205898e-01],\n",
       "       [ 1.37000000e+02,  4.00000000e+01,  3.50000000e+01, ...,\n",
       "         1.49119849e+00,  5.06866512e+00, -4.42982539e-02]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapper.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Models\n",
    "\n",
    "Now that we've cleaned and preprocessed our dataset, we're ready to fit some models!\n",
    "\n",
    "In the cell below:\n",
    "\n",
    "* Create an `AdaBoostClassifier`\n",
    "* Create a `GradientBoostingClassifer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_clf = AdaBoostClassifier()\n",
    "gbt_clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train each of the classifiers using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create some predictions using each model so that we can calculate the training and testing accuracy for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost_train_preds = adaboost_clf.predict(X_train)\n",
    "adaboost_test_preds = adaboost_clf.predict(X_test)\n",
    "gbt_clf_train_preds = gbt_clf.predict(X_train)\n",
    "gbt_clf_test_preds = gbt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, complete the following function and use it to calculate the training and testing accuracy and f1-score for each model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.8489583333333334\n",
      "F1-Score: 0.7808564231738034\n",
      "\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.9270833333333334\n",
      "F1-Score: 0.8944723618090453\n",
      "\n",
      "Testing Metrics\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.6979166666666666\n",
      "F1-Score: 0.4727272727272727\n",
      "\n",
      "Model: Gradient Boosted Trees\n",
      "Accuracy: 0.7552083333333334\n",
      "F1-Score: 0.584070796460177\n"
     ]
    }
   ],
   "source": [
    "def display_acc_and_f1_score(true, preds, model_name):\n",
    "    acc = accuracy_score(true, preds)\n",
    "    f1 = f1_score(true, preds)\n",
    "    print(\"Model: {}\".format(model_name))\n",
    "    print(\"Accuracy: {}\".format(acc))\n",
    "    print(\"F1-Score: {}\".format(f1))\n",
    "    \n",
    "print(\"Training Metrics\")\n",
    "display_acc_and_f1_score(y_train, adaboost_train_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_train, gbt_clf_train_preds, model_name='Gradient Boosted Trees')\n",
    "print(\"\")\n",
    "print(\"Testing Metrics\")\n",
    "display_acc_and_f1_score(y_test, adaboost_test_preds, model_name='AdaBoost')\n",
    "print(\"\")\n",
    "display_acc_and_f1_score(y_test, gbt_clf_test_preds, model_name='Gradient Boosted Trees')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go one step further and create a confusion matrix and classification report for each. Do so in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108,  19],\n",
       "       [ 39,  26]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_confusion_matrix = confusion_matrix(y_test, adaboost_test_preds)\n",
    "adaboost_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112,  15],\n",
       "       [ 32,  33]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_confusion_matrix = confusion_matrix(y_test, gbt_clf_test_preds)\n",
    "gbt_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79       127\n",
      "           1       0.58      0.40      0.47        65\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       192\n",
      "   macro avg       0.66      0.63      0.63       192\n",
      "weighted avg       0.68      0.70      0.68       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_classification_report = classification_report(y_test, adaboost_test_preds)\n",
    "print(adaboost_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83       127\n",
      "           1       0.69      0.51      0.58        65\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       192\n",
      "   macro avg       0.73      0.69      0.71       192\n",
      "weighted avg       0.75      0.76      0.74       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_classification_report = classification_report(y_test, gbt_clf_test_preds)\n",
    "print(gbt_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Question:_** How did the models perform? Interpret the evaluation metrics above to answer this question.\n",
    "\n",
    "Write your answer below this line:\n",
    "_______________________________________________________________________________________________________________________________\n",
    "\n",
    " \n",
    " \n",
    "As a final performance check, let's calculate the `cross_val_score` for each model! Do so now in the cells below. \n",
    "\n",
    "Recall that to compute the cross validation score, we need to pass in:\n",
    "\n",
    "* a classifier\n",
    "* All training Data\n",
    "* All labels\n",
    "* The number of folds we want in our cross validation score. \n",
    "\n",
    "Since we're computing cross validation score, we'll want to pass in the entire (scaled) dataset, as well as all of the labels. We don't need to give it data that has been split into training and testing sets because it will handle this step during the cross validation. \n",
    "\n",
    "In the cells below, compute the mean cross validation score for each model. For the data, use our `scaled_df` variable. The corresponding labels are in the variable `target`. Also set `cv=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Adaboost Cross-Val Score (k=5):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a2f6b35025ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean Adaboost Cross-Val Score (k=5):'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madaboost_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Expected Output: 0.7631270690094218\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "print('Mean Adaboost Cross-Val Score (k=5):')\n",
    "print(cross_val_score(adaboost_clf, df, target, cv=5))\n",
    "# Expected Output: 0.7631270690094218"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean GBT Cross-Val Score (k=5):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_val_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ff0b53b93a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean GBT Cross-Val Score (k=5):'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbt_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Expected Output: 0.7591715474068416\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_val_score' is not defined"
     ]
    }
   ],
   "source": [
    "print('Mean GBT Cross-Val Score (k=5):')\n",
    "print(cross_val_score(gbt_clf, df, target, cv=5))\n",
    "# Expected Output: 0.7591715474068416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These models didn't do poorly, but we could probably do a bit better by tuning some of the important parameters such as the **_Learning Rate_**. \n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, we learned how to use scikit-learn's implementations of popular boosting algorithms such as AdaBoost and Gradient Boosted Trees to make classification predictions on a real-world dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
